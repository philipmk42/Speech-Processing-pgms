{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnhigJfF4GQ1",
        "outputId": "5417fa0c-f934-4918-d781-603a5145ad3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Hidden Markov Model parameters ===\n",
            "Initial probabilities (pi):\n",
            " /s/  /p/  /ie:/  /tS/\n",
            " 1.0  0.0    0.0   0.0\n",
            "\n",
            "Transition matrix A (rows = from-state, cols = to-state):\n",
            "       /s/  /p/  /ie:/  /tS/\n",
            "/s/    0.0  0.9   0.10  0.00\n",
            "/p/    0.0  0.0   0.95  0.05\n",
            "/ie:/  0.0  0.0   0.20  0.80\n",
            "/tS/   0.0  0.0   0.00  1.00\n",
            "\n",
            "Emission matrix B (rows = state, cols = observation):\n",
            "       Energy  Pitch  Duration\n",
            "/s/       0.7    0.2       0.1\n",
            "/p/       0.5    0.3       0.2\n",
            "/ie:/     0.3    0.5       0.2\n",
            "/tS/      0.4    0.4       0.2\n",
            "\n",
            "=== Sampling a single sequence (phonemes + observations) ===\n",
            "Generated phoneme sequence: [np.str_('/s/'), np.str_('/p/'), np.str_('/ie:/'), np.str_('/ie:/')]\n",
            "Generated observation sequence: [np.str_('Duration'), np.str_('Pitch'), np.str_('Energy'), np.str_('Duration')]\n",
            "\n",
            "=== Viterbi inference ===\n",
            "Observations given to Viterbi     : [np.str_('Duration'), np.str_('Pitch'), np.str_('Energy'), np.str_('Duration')]\n",
            "Viterbi-decoded phoneme sequence : ['/s/', '/p/', '/ie:/', '/tS/']\n",
            "Log-probability of decoded path  : -6.6998\n",
            "\n",
            "Do the generated (true) states match the Viterbi-decoded states? -> False\n",
            "\n",
            "Delta (log probs) at each time step (rows = time t):\n",
            "      /s/     /p/   /ie:/    /tS/\n",
            "0  -2.303 -29.240 -29.240 -29.240\n",
            "1 -31.543  -3.612  -5.298 -30.157\n",
            "2 -31.600 -31.936  -4.867  -6.438\n",
            "3 -34.801 -33.314  -8.086  -6.700\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Hidden Markov Model lab (single cell, Colab-ready)\n",
        "# Implements: parameter representation, display, sampling (generate sequence),\n",
        "# and Viterbi inference for the phonemes of the word \"speech\".\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(42)  # for reproducible runs; change/remove if you want randomness\n",
        "\n",
        "# 1) Define states (phonemes) and observations\n",
        "states = ['/s/', '/p/', '/ie:/', '/tS/']          # hidden states (phonemes)\n",
        "observations = ['Energy', 'Pitch', 'Duration']   # discrete observation symbols\n",
        "\n",
        "n_states = len(states)\n",
        "n_obs = len(observations)\n",
        "\n",
        "# 2) HMM parameters\n",
        "# (a) Initial probabilities: start in /s/ with probability 1\n",
        "pi = np.array([1.0, 0.0, 0.0, 0.0])   # order matches `states`\n",
        "\n",
        "# (b) Transition probability matrix (rows = from-state, cols = to-state)\n",
        "# We will define a plausible transition matrix for the word \"speech\"\n",
        "# A sample table consistent with the idea of the phoneme order in \"speech\".\n",
        "A = np.array([\n",
        "    # to:   /s/   /p/   /ie:/  /tS/\n",
        "    [0.0,  0.9,  0.1,   0.0],   # from /s/\n",
        "    [0.0,  0.0,  0.95,  0.05],  # from /p/\n",
        "    [0.0,  0.0,  0.2,   0.8],   # from /ie:/\n",
        "    [0.0,  0.0,  0.0,   1.0]    # from /tS/ (terminal loop to itself if needed)\n",
        "], dtype=float)\n",
        "\n",
        "# (c) Emission probability matrix: P(observation | state)\n",
        "# rows = states, columns = observations\n",
        "B = np.array([\n",
        "    # Energy Pitch Duration\n",
        "    [0.7,   0.2,  0.1],   # /s/\n",
        "    [0.5,   0.3,  0.2],   # /p/\n",
        "    [0.3,   0.5,  0.2],   # /ie:/\n",
        "    [0.4,   0.4,  0.2]    # /tS/\n",
        "], dtype=float)\n",
        "\n",
        "# Utility dictionaries for indices\n",
        "state_idx = {s: i for i, s in enumerate(states)}\n",
        "obs_idx = {o: i for i, o in enumerate(observations)}\n",
        "\n",
        "# 3) Display function for matrices and initial probabilities\n",
        "def display_hmm(pi, A, B, states, observations):\n",
        "    print(\"Initial probabilities (pi):\")\n",
        "    display_df = pd.DataFrame(pi.reshape(1, -1), columns=states)\n",
        "    print(display_df.to_string(index=False))\n",
        "    print(\"\\nTransition matrix A (rows = from-state, cols = to-state):\")\n",
        "    dfA = pd.DataFrame(A, index=states, columns=states)\n",
        "    print(dfA.to_string())\n",
        "    print(\"\\nEmission matrix B (rows = state, cols = observation):\")\n",
        "    dfB = pd.DataFrame(B, index=states, columns=observations)\n",
        "    print(dfB.to_string())\n",
        "\n",
        "# 4) Sampling: generate a single sequence of states and observations\n",
        "def sample_hmm(pi, A, B, states, observations, max_len=4):\n",
        "    \"\"\"\n",
        "    Generate a sequence of hidden states (phonemes) and observations (symbols).\n",
        "    For the word 'speech' we set max_len=4 (s, p, ie:, tS) by default.\n",
        "    \"\"\"\n",
        "    curr_state = np.random.choice(states, p=pi)  # should be '/s/' as pi has all mass there\n",
        "    state_sequence = [curr_state]\n",
        "    obs_sequence = []\n",
        "    # Emit observation for the starting state\n",
        "    s_idx = state_idx[curr_state]\n",
        "    obs_symbol = np.random.choice(observations, p=B[s_idx])\n",
        "    obs_sequence.append(obs_symbol)\n",
        "\n",
        "    for _ in range(1, max_len):\n",
        "        # transition from current state\n",
        "        from_idx = state_idx[curr_state]\n",
        "        next_state = np.random.choice(states, p=A[from_idx])\n",
        "        state_sequence.append(next_state)\n",
        "        # emit observation from next_state\n",
        "        obs_symbol = np.random.choice(observations, p=B[state_idx[next_state]])\n",
        "        obs_sequence.append(obs_symbol)\n",
        "        curr_state = next_state\n",
        "    return state_sequence, obs_sequence\n",
        "\n",
        "# 5) Viterbi algorithm for inference (most likely state path given observations)\n",
        "def viterbi(pi, A, B, obs_seq, states, observations):\n",
        "    T = len(obs_seq)\n",
        "    N = len(states)\n",
        "    # index observation sequence\n",
        "    obs_indices = [obs_idx[o] for o in obs_seq]\n",
        "\n",
        "    # delta[t, i] = highest log-prob of any path that ends in state i at time t\n",
        "    # psi[t, i] = argmax previous state at time t-1 leading to i\n",
        "    log_pi = np.log(pi + 1e-12)          # small epsilon avoid log(0)\n",
        "    log_A = np.log(A + 1e-12)\n",
        "    log_B = np.log(B + 1e-12)\n",
        "\n",
        "    delta = np.full((T, N), -np.inf)\n",
        "    psi = np.zeros((T, N), dtype=int)\n",
        "\n",
        "    # initialization t=0\n",
        "    delta[0] = log_pi + log_B[:, obs_indices[0]]\n",
        "    psi[0] = 0\n",
        "\n",
        "    # recursion\n",
        "    for t in range(1, T):\n",
        "        for j in range(N):\n",
        "            # compute max over i: delta[t-1,i] + log_A[i,j]\n",
        "            scores = delta[t-1] + log_A[:, j]\n",
        "            psi[t, j] = np.argmax(scores)\n",
        "            delta[t, j] = scores[psi[t, j]] + log_B[j, obs_indices[t]]\n",
        "\n",
        "    # termination - backtrack\n",
        "    path = np.zeros(T, dtype=int)\n",
        "    path[T-1] = np.argmax(delta[T-1])\n",
        "    for t in range(T-2, -1, -1):\n",
        "        path[t] = psi[t+1, path[t+1]]\n",
        "\n",
        "    decoded_states = [states[i] for i in path]\n",
        "    max_log_prob = np.max(delta[T-1])\n",
        "    return decoded_states, max_log_prob, delta, psi\n",
        "\n",
        "# === Run everything and print outputs ===\n",
        "print(\"=== Hidden Markov Model parameters ===\")\n",
        "display_hmm(pi, A, B, states, observations)\n",
        "\n",
        "print(\"\\n=== Sampling a single sequence (phonemes + observations) ===\")\n",
        "gen_states, gen_obs = sample_hmm(pi, A, B, states, observations, max_len=4)\n",
        "print(\"Generated phoneme sequence:\", gen_states)\n",
        "print(\"Generated observation sequence:\", gen_obs)\n",
        "\n",
        "# Run Viterbi to infer states from the observations\n",
        "decoded_states, log_prob, delta, psi = viterbi(pi, A, B, gen_obs, states, observations)\n",
        "print(\"\\n=== Viterbi inference ===\")\n",
        "print(\"Observations given to Viterbi     :\", gen_obs)\n",
        "print(\"Viterbi-decoded phoneme sequence :\", decoded_states)\n",
        "print(f\"Log-probability of decoded path  : {log_prob:.4f}\")\n",
        "\n",
        "# Show comparison\n",
        "correct = all(a == b for a, b in zip(gen_states, decoded_states))\n",
        "print(\"\\nDo the generated (true) states match the Viterbi-decoded states? ->\", correct)\n",
        "\n",
        "# (Optional) show the delta table as a pandas DataFrame for inspection\n",
        "delta_df = pd.DataFrame(delta, columns=states)\n",
        "print(\"\\nDelta (log probs) at each time step (rows = time t):\")\n",
        "print(delta_df.to_string(float_format=lambda x: f\"{x:.3f}\"))"
      ]
    }
  ]
}