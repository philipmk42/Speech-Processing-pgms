{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMRyeJCG0Hyc",
        "outputId": "1ace206a-9fda-4713-8dca-6792b16d53bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded audio: hello.wav\n",
            "Sample rate: 22050 Hz\n",
            "Number of frames (MFCC): 42\n",
            "\n",
            "First 20 observation symbols (0→O1, 1→O2, 2→O3, 3→O4):\n",
            "[1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "===== VITERBI DECODING RESULT =====\n",
            "Length of observation sequence: 42 frames\n",
            "\n",
            "Most likely hidden state sequence (indices):\n",
            "[np.int64(0), np.int64(1), np.int64(1), np.int64(2), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3)] ...\n",
            "\n",
            "Most likely hidden state sequence (state names):\n",
            "['S1', 'S2', 'S2', 'S3', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4', 'S4'] ...\n",
            "\n",
            "Most likely phoneme sequence for first 50 frames:\n",
            "['/h/', '/e/', '/e/', '/l/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/', '/o/'] ...\n",
            "\n",
            "Probability of this most likely path:\n",
            "4.3813456718993237e-26\n",
            "\n",
            "Segment-wise majority phonemes (approx. H-E-L-L/O pattern):\n",
            "[np.str_('/o/'), np.str_('/o/'), np.str_('/o/'), np.str_('/o/')]\n",
            "\n",
            "Inference: The segment-wise decoded pattern is:\n",
            "[np.str_('/o/'), np.str_('/o/'), np.str_('/o/'), np.str_('/o/')]\n",
            "This is the most likely phoneme sequence the HMM associates with this recording.\n"
          ]
        }
      ],
      "source": [
        "# =============================================\n",
        "# FULL END-TO-END VITERBI DEMO FOR \"HELLO\"\n",
        "# =============================================\n",
        "\n",
        "# 1) INSTALL & IMPORT LIBRARIES\n",
        "!pip install librosa soundfile scikit-learn --quiet\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# =========================\n",
        "# HMM DEFINITION\n",
        "# =========================\n",
        "\n",
        "# Hidden states (phonemes)\n",
        "states = [\"S1\", \"S2\", \"S3\", \"S4\"]\n",
        "state_labels = [\"/h/\", \"/e/\", \"/l/\", \"/o/\"]  # for nice printing\n",
        "num_states = len(states)\n",
        "\n",
        "# Transition probability matrix A (from rows -> to cols)\n",
        "A = np.array([\n",
        "    [0.0, 0.7, 0.3, 0.0],  # from S1 (/h/)\n",
        "    [0.0, 0.2, 0.6, 0.2],  # from S2 (/e/)\n",
        "    [0.0, 0.0, 0.3, 0.7],  # from S3 (/l/)\n",
        "    [0.0, 0.0, 0.1, 0.9]   # from S4 (/o/)\n",
        "])\n",
        "\n",
        "# Emission probability matrix B (Si emits Oj)\n",
        "# rows: S1..S4, cols: O1..O4\n",
        "B = np.array([\n",
        "    [0.6, 0.2, 0.1, 0.1],  # S1\n",
        "    [0.1, 0.7, 0.1, 0.1],  # S2\n",
        "    [0.1, 0.1, 0.6, 0.2],  # S3\n",
        "    [0.2, 0.1, 0.2, 0.5]   # S4\n",
        "])\n",
        "\n",
        "# Initial probabilities (π) – we always start in /h/\n",
        "pi = np.array([1.0, 0.0, 0.0, 0.0])\n",
        "\n",
        "# =========================\n",
        "# 2) LOAD AUDIO & EXTRACT FEATURES\n",
        "# =========================\n",
        "\n",
        "# --- Load your recorded \"hello\" ---\n",
        "# Upload `hello.wav` in Colab (left panel: Files → upload).\n",
        "audio_path = \"hello.wav\"\n",
        "\n",
        "y, sr = librosa.load(audio_path, sr=None)  # keep original sample rate\n",
        "\n",
        "# Optional: trim leading/trailing silence\n",
        "y, _ = librosa.effects.trim(y, top_db=30)\n",
        "\n",
        "# --- Frame-level MFCC extraction ---\n",
        "# Use a standard 25 ms window, 10 ms hop\n",
        "frame_length = int(0.025 * sr)\n",
        "hop_length   = int(0.010 * sr)\n",
        "\n",
        "# 13 MFCCs per frame (common choice)\n",
        "mfcc = librosa.feature.mfcc(\n",
        "    y=y, sr=sr, n_mfcc=13, n_fft=frame_length, hop_length=hop_length\n",
        ")  # shape: (13, num_frames)\n",
        "\n",
        "# Transpose to shape (num_frames, 13)\n",
        "mfcc_frames = mfcc.T\n",
        "num_frames = mfcc_frames.shape[0]\n",
        "\n",
        "print(f\"Loaded audio: {audio_path}\")\n",
        "print(f\"Sample rate: {sr} Hz\")\n",
        "print(f\"Number of frames (MFCC): {num_frames}\")\n",
        "\n",
        "# =========================\n",
        "# 3) VECTOR QUANTIZATION -> DISCRETE OBSERVATIONS\n",
        "# =========================\n",
        "\n",
        "# We use KMeans to quantize MFCC frames into 4 clusters.\n",
        "# Each cluster corresponds to an observation symbol O1..O4.\n",
        "\n",
        "num_observations = 4  # O1, O2, O3, O4\n",
        "\n",
        "kmeans = KMeans(n_clusters=num_observations, random_state=42, n_init=10)\n",
        "kmeans.fit(mfcc_frames)\n",
        "\n",
        "# Labels for each frame: values in {0,1,2,3}\n",
        "obs_seq = kmeans.labels_.tolist()\n",
        "\n",
        "print(\"\\nFirst 20 observation symbols (0→O1, 1→O2, 2→O3, 3→O4):\")\n",
        "print(obs_seq[:20])\n",
        "\n",
        "# =========================\n",
        "# 4) VITERBI ALGORITHM\n",
        "# =========================\n",
        "\n",
        "def viterbi(obs, A, B, pi):\n",
        "    \"\"\"\n",
        "    obs : list of observation indices (0..M-1)\n",
        "    A   : NxN transition matrix\n",
        "    B   : NxM emission matrix\n",
        "    pi  : length-N initial distribution\n",
        "    \"\"\"\n",
        "    N = A.shape[0]       # number of states\n",
        "    T = len(obs)         # length of observation sequence\n",
        "\n",
        "    # delta[t, i]: best probability of any path ending in state i at time t\n",
        "    delta = np.zeros((T, N))\n",
        "    # psi[t, i]: argmax previous state index that leads to i at time t\n",
        "    psi = np.zeros((T, N), dtype=int)\n",
        "\n",
        "    # 1) Initialization\n",
        "    delta[0, :] = pi * B[:, obs[0]]\n",
        "    psi[0, :] = 0\n",
        "\n",
        "    # 2) Recursion\n",
        "    for t in range(1, T):\n",
        "        for j in range(N):\n",
        "            probs = delta[t - 1, :] * A[:, j]   # from all i -> j\n",
        "            psi[t, j] = np.argmax(probs)\n",
        "            delta[t, j] = probs[psi[t, j]] * B[j, obs[t]]\n",
        "\n",
        "    # 3) Termination\n",
        "    best_last_state = np.argmax(delta[T - 1, :])\n",
        "    best_prob = delta[T - 1, best_last_state]\n",
        "\n",
        "    # 4) Path backtracking\n",
        "    best_path = [best_last_state]\n",
        "    for t in range(T - 1, 0, -1):\n",
        "        best_last_state = psi[t, best_last_state]\n",
        "        best_path.insert(0, best_last_state)\n",
        "\n",
        "    return best_path, best_prob, delta, psi\n",
        "\n",
        "# Run Viterbi on the full observation sequence from the audio\n",
        "best_path, best_prob, delta, psi = viterbi(obs_seq, A, B, pi)\n",
        "\n",
        "# Map state indices → phoneme labels\n",
        "best_states = [states[i] for i in best_path]\n",
        "best_phonemes = [state_labels[i] for i in best_path]\n",
        "\n",
        "# =========================\n",
        "# 5) PRINT RESULTS\n",
        "# =========================\n",
        "\n",
        "print(\"\\n===== VITERBI DECODING RESULT =====\")\n",
        "print(f\"Length of observation sequence: {len(obs_seq)} frames\")\n",
        "\n",
        "print(\"\\nMost likely hidden state sequence (indices):\")\n",
        "print(best_path[:50], \"...\")  # print first 50 to keep it short\n",
        "\n",
        "print(\"\\nMost likely hidden state sequence (state names):\")\n",
        "print(best_states[:50], \"...\")\n",
        "\n",
        "print(\"\\nMost likely phoneme sequence for first 50 frames:\")\n",
        "print(best_phonemes[:50], \"...\")\n",
        "\n",
        "print(\"\\nProbability of this most likely path:\")\n",
        "print(best_prob)\n",
        "\n",
        "# Simple high-level inference (frame-wise):\n",
        "# We can summarize by taking the majority phoneme in four equal segments\n",
        "segments = 4\n",
        "segment_len = len(best_phonemes) // segments\n",
        "segment_summary = []\n",
        "\n",
        "for i in range(segments):\n",
        "    start = i * segment_len\n",
        "    end = (i + 1) * segment_len if i < segments - 1 else len(best_phonemes)\n",
        "    segment = best_phonemes[start:end]\n",
        "    # majority phoneme in this segment\n",
        "    values, counts = np.unique(segment, return_counts=True)\n",
        "    majority = values[np.argmax(counts)]\n",
        "    segment_summary.append(majority)\n",
        "\n",
        "print(\"\\nSegment-wise majority phonemes (approx. H-E-L-L/O pattern):\")\n",
        "print(segment_summary)\n",
        "\n",
        "if segment_summary == [\"/h/\", \"/e/\", \"/l/\", \"/o/\"]:\n",
        "    print(\"\\nInference: Segment-wise decoding strongly matches /h/ /e/ /l/ /o/,\")\n",
        "    print(\"so the HMM with Viterbi successfully recognizes the word 'hello'.\")\n",
        "else:\n",
        "    print(\"\\nInference: The segment-wise decoded pattern is:\")\n",
        "    print(segment_summary)\n",
        "    print(\"This is the most likely phoneme sequence the HMM associates with this recording.\")\n"
      ]
    }
  ]
}